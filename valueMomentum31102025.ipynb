{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX9eQv9wpQ3sxCF3gisTJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anvy87/AlgoTrading/blob/master/valueMomentum31102025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "icpsFL16x89l",
        "outputId": "3fa582b0-7631-4a68-fde9-b20126ac5410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting beautifulsoup4==4.11.2\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4==4.11.2) (2.8)\n",
            "Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: beautifulsoup4\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.5\n",
            "    Uninstalling beautifulsoup4-4.13.5:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.5\n",
            "Successfully installed beautifulsoup4-4.11.2\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4==4.11.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dJd0JWdWx95E",
        "outputId": "ea0bf67e-1250-42a9-a123-4fc401a27748"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DSekhivZyI7x",
        "outputId": "8ece9834-d279-4062-aa39-e589531ca027"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import logging"
      ],
      "metadata": {
        "id": "t3brjcDPyJip"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_logging():\n",
        "    # Configure Application Logging\n",
        "    log_filepath = \"ToolsLog.log\"\n",
        "    format = \"%(asctime)s: - %(levelname)s - %(message)s\"\n",
        "    logging.basicConfig(\n",
        "            filename=log_filepath,\n",
        "            format=format,\n",
        "            level=logging.INFO,\n",
        "            datefmt=\"%Y-%m-%d %H:%M:%S\")"
      ],
      "metadata": {
        "id": "mUJFaYFCyOOX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_screener_data(link):\n",
        "    cache_index = None\n",
        "    data = pd.DataFrame()\n",
        "    current_page = 1\n",
        "    page_limit = 25\n",
        "    while current_page < page_limit:\n",
        "        if current_page == 1:\n",
        "            url=link\n",
        "        else:\n",
        "            url = f'{link}?page={current_page}'\n",
        "        all_tables = pd.read_html(url, flavor='bs4')\n",
        "        combined_df = pd.concat(all_tables)\n",
        "        combined_df = combined_df.drop(\n",
        "            combined_df[combined_df['S.No.'].isnull()].index)\n",
        "        # print(combined_df)\n",
        "        # if cache_index == combined_df.iloc[-2]['S.No.']:\n",
        "        if len(combined_df.index) < 26:\n",
        "            data = pd.concat([data, combined_df], axis=0)\n",
        "            break\n",
        "        # cache_index = combined_df.iloc[-2]['S.No.']\n",
        "        # print(cache_index)\n",
        "        data = pd.concat([data, combined_df], axis=0)\n",
        "        current_page += 1\n",
        "        time.sleep(1)\n",
        "    data = data.iloc[0:].drop(data[data['S.No.'] == 'S.No.'].index)\n",
        "    return data"
      ],
      "metadata": {
        "id": "j0IqKWmyyRWb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "UXeWFQPTyWdl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configure_logging()\n",
        "logging.info(\"Tools : Trending Value Screen extract commenced\")"
      ],
      "metadata": {
        "id": "M6sh3eJvyZ9_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch PE/PB/Dividend Yield Value Ratio\n",
        "pbv_link = 'https://www.screener.in/screens/2112737/trendvalue_pricebookvalue/'\n",
        "pbv_df = fetch_screener_data(pbv_link)\n",
        "pbv_df = pbv_df[['Name','P/E', 'Div Yld  %', 'CMP / BV']]\n",
        "pbv_df['P/E'] = pd.to_numeric(pbv_df['P/E'], errors='coerce')\n",
        "pbv_df['Div Yld  %'] = pd.to_numeric(pbv_df['Div Yld  %'], errors='coerce')\n",
        "pbv_df['CMP / BV'] = pd.to_numeric(pbv_df['CMP / BV'], errors='coerce')\n",
        "pbv_df['P/E'] = pbv_df['P/E'].fillna(100000)\n",
        "pbv_df['CMP / BV'] = pbv_df['CMP / BV'].fillna(100000)\n",
        "pbv_df['Div Yld  %'] = pbv_df['Div Yld  %'].fillna(0)\n",
        "# pbv_df.to_excel('D:/pbv.xlsx', index=False)\n",
        "pbv_df.dropna(inplace=True)\n",
        "pbv_df = pbv_df[pbv_df['P/E'] > 0]\n",
        "pbv_df = pbv_df[pbv_df['Div Yld  %'] > 0]\n",
        "merged_df = pbv_df"
      ],
      "metadata": {
        "id": "c2V0bDluycoH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Price to Free Cash Flow\n",
        "cashflow_link = 'https://www.screener.in/screens/2112756/trendvalue_cashflow/'\n",
        "cf_df = fetch_screener_data(cashflow_link)\n",
        "cf_df = cf_df[['Name','CMP / OCF']]\n",
        "cf_df['CMP / OCF'] = pd.to_numeric(cf_df['CMP / OCF'], errors='coerce')\n",
        "cf_df['CMP / OCF'] = cf_df['CMP / OCF'].fillna(100000)\n",
        "# cf_df.to_excel('D:/cashflow.xlsx', index=False)\n",
        "cf_df.dropna(inplace=True)\n",
        "cf_df = cf_df[cf_df['CMP / OCF'] > 0]\n",
        "merged_df = pd.merge(merged_df, cf_df, on='Name', how='inner')\n",
        "# print(\"Free Cash Flow data extraction complete\")"
      ],
      "metadata": {
        "id": "7MBH0ENvyulL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch EV to EBITDA\n",
        "ev_link = 'https://www.screener.in/screens/2112767/trendvalue_ev/'\n",
        "ev_df = fetch_screener_data(ev_link)\n",
        "ev_df = ev_df[['Name','EV / EBITDA']]\n",
        "ev_df['EV / EBITDA'] = pd.to_numeric(ev_df['EV / EBITDA'], errors='coerce')\n",
        "ev_df['EV / EBITDA'] = ev_df['EV / EBITDA'].fillna(100000)\n",
        "# ev_df.to_excel('D:/ev.xlsx', index=False)\n",
        "ev_df.dropna(inplace=True)\n",
        "ev_df = ev_df[ev_df['EV / EBITDA'] > 0]\n",
        "merged_df = pd.merge(merged_df, ev_df, on='Name', how='inner')\n",
        "# print(\"EV to EBDITA data extraction complete\")"
      ],
      "metadata": {
        "id": "pG1CdN1Xyy1_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Price to Sales ratio\n",
        "sales_link = 'https://www.screener.in/screens/2112772/trendvalue_pricesales/'\n",
        "sales_df = fetch_screener_data(sales_link)\n",
        "sales_df = sales_df[['Name','CMP / Sales']]\n",
        "sales_df['CMP / Sales'] = pd.to_numeric(sales_df['CMP / Sales'], errors='coerce')\n",
        "sales_df['CMP / Sales'] = sales_df['CMP / Sales'].fillna(100000)\n",
        "# sales_df.to_excel('D:/sales.xlsx', index=False)\n",
        "sales_df.dropna(inplace=True)\n",
        "sales_df = sales_df[sales_df['CMP / Sales'] > 0]\n",
        "# print(\"Price to Sales Ratio data extraction complete\")"
      ],
      "metadata": {
        "id": "OlCzFD_dy6qx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Last 6 months return (Momentum)\n",
        "momentum_link = 'https://www.screener.in/screens/2112742/trendvalue_momentum/'\n",
        "mo_df = fetch_screener_data(momentum_link)\n",
        "mo_df = mo_df[['Name','6mth return  %']]\n",
        "mo_df['6mth return  %'] = pd.to_numeric(mo_df['6mth return  %'], errors='coerce')\n",
        "mo_df['6mth return  %'] = mo_df['6mth return  %'].fillna(-100000)\n",
        "# mo_df.to_excel('D:/mo.xlsx', index=False)\n",
        "mo_df.dropna(inplace=True)\n",
        "mo_df = mo_df[mo_df['6mth return  %'] > 0]\n",
        "merged_df = pd.merge(merged_df, mo_df, on='Name', how='inner')\n",
        "# print(\"Momentum / 6 month Returns data extraction complete\")"
      ],
      "metadata": {
        "id": "BdcrZgCey-WS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Merged dataset\n",
        "merged_df = pd.merge(merged_df, sales_df, on='Name', how='inner')\n",
        "merged_df = merged_df.rename(columns={\n",
        "    'Name': 'Stock',\n",
        "    'P/E': 'PE',\n",
        "    'Div Yld  %': 'Div',\n",
        "    'CMP / BV': 'BV',\n",
        "    'CMP / OCF': 'Cashflow',\n",
        "    'EV / EBITDA': 'EV',\n",
        "    'CMP / Sales': 'Sales',\n",
        "    '6mth return  %': '6mo Return'\n",
        "})\n",
        "merged_df['PE'] = merged_df['PE'].map(lambda x: float(x))\n",
        "merged_df['Div'] = merged_df['Div'].map(lambda x: float(x))\n",
        "merged_df['BV'] = merged_df['BV'].map(lambda x: float(x))\n",
        "merged_df['6mo Return'] = merged_df['6mo Return'].map(lambda x: float(x))\n",
        "# merged_df['3mo Return'] = merged_df['3mo Return'].map(lambda x: float(x))\n",
        "merged_df['Cashflow'] = merged_df['Cashflow'].map(lambda x: float(x))\n",
        "merged_df['EV'] = merged_df['EV'].map(lambda x: float(x))\n",
        "merged_df['Sales'] = merged_df['Sales'].map(lambda x: float(x))"
      ],
      "metadata": {
        "id": "Syh6sPeAzBj4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Decile for PE\n",
        "merged_df['PE_Rank'] = merged_df['PE'].rank()\n",
        "merged_df['PE_Decile'] = pd.qcut(merged_df['PE_Rank'], q=10, labels=False, duplicates='drop') + 1\n",
        "# Apply Decile for Div\n",
        "merged_df['Div_Rank'] = merged_df['Div'].rank(ascending=False)\n",
        "merged_df['Div_Decile'] = pd.qcut(merged_df['Div_Rank'], q=10, labels=False, duplicates='drop') + 1\n",
        "# Apply Decile for BV\n",
        "merged_df['BV_Rank'] = merged_df['BV'].rank()\n",
        "merged_df['BV_Decile'] = pd.qcut(merged_df['BV_Rank'], q=10, labels=False, duplicates='drop') + 1\n",
        "# Apply Decile for Cashflow\n",
        "merged_df['Cashflow_Rank'] = merged_df['Cashflow'].rank()\n",
        "merged_df['Cashflow_Decile'] = pd.qcut(merged_df['Cashflow_Rank'], q=10, labels=False, duplicates='drop') + 1\n",
        "# Apply Decile for EV\n",
        "merged_df['EV_Rank'] = merged_df['EV'].rank()\n",
        "merged_df['EV_Decile'] = pd.qcut(merged_df['EV_Rank'], q=10, labels=False, duplicates='drop') + 1\n",
        "# Apply Decile for Sales\n",
        "merged_df['Sales_Rank'] = merged_df['Sales'].rank()\n",
        "merged_df['Sales_Decile'] = pd.qcut(merged_df['Sales_Rank'], q=10, labels=False, duplicates='drop') + 1"
      ],
      "metadata": {
        "id": "tzayTRMEzIGY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consolidated_Rank column\n",
        "merged_df['Consolidated_Rank'] = merged_df['PE_Decile'] + merged_df['Div_Decile'] + merged_df['BV_Decile'] + merged_df['Cashflow_Decile'] + merged_df['EV_Decile'] + merged_df['Sales_Decile']"
      ],
      "metadata": {
        "id": "AsIOq2dWzNfL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retain only stocks that has given a postive return in the last 6 months\n",
        "merged_df = merged_df[merged_df['6mo Return'] > 0]"
      ],
      "metadata": {
        "id": "-ZpGDYyOzZUb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgFF2EeK1Ycq",
        "outputId": "7598bdd4-9b28-49c8-999c-de173a33e982"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decile on consolidated rank\n",
        "merged_df['Consolidated_Decile'] = pd.qcut(merged_df['Consolidated_Rank'], q=10, labels=False, duplicates='drop') + 1\n",
        "#merged_df = merged_df.sort_values(by=['Consolidated_Decile', '6mo Return'], ascending=[True, False])\n",
        "merged_df.to_excel('/content/drive/MyDrive/merged31102025.xlsx', index=False)"
      ],
      "metadata": {
        "id": "Xrkf3Gnpzc6-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retain only rows in the first decile of Consolidated_Decile\n",
        "df_final = merged_df[merged_df['Consolidated_Decile'] == 1]\n",
        "df_final = df_final.sort_values(by=['6mo Return'], ascending=False)\n",
        "df_final = df_final.head(40)\n",
        "df_final.to_excel('/content/drive/MyDrive/final31102025.xlsx', index=False)\n",
        "print(\"Final Dataset\")\n",
        "print(df_final)\n",
        "logging.info(\"Tools : Trending Value Screen extract completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJOIePTyz4fn",
        "outputId": "876ae807-2d68-4a37-e0fa-0fe7ad4231e5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Dataset\n",
            "                Stock     PE   Div    BV  Cashflow     EV  6mo Return  Sales  \\\n",
            "119     Indian Metals  18.13  1.66  2.76     11.09  12.03      110.28   2.55   \n",
            "51      Hero Motocorp  22.02  2.98  5.75     25.81  14.71       43.16   2.74   \n",
            "37       Sharda Motor  18.66  1.57  5.50     21.94  11.91       32.39   2.04   \n",
            "73    Jenburkt Pharma  17.02  1.41  3.07     20.07  11.22       29.11   3.53   \n",
            "45     Uni Abex Alloy  20.21  1.07  4.55     18.80  12.92       28.00   3.42   \n",
            "121      Welspun Corp  14.35  0.52  3.11     16.93   9.33       27.32   1.65   \n",
            "136      Ador Welding  33.65  1.87  3.79     13.60  17.71       24.40   1.67   \n",
            "118  Expleo Solutions  15.78  4.93  2.48      8.76   7.74       23.79   1.53   \n",
            "94      Nitta Gelatin  10.90  0.67  1.93     10.82   6.14       19.79   1.51   \n",
            "142  L G Balakrishnan  14.90  1.41  2.37     15.69   8.41       16.11   1.62   \n",
            "64     Maithan Alloys   4.53  1.45  0.86     64.57   3.64       16.03   1.56   \n",
            "133      Siyaram Silk  17.82  1.60  2.65     13.32  10.44       15.86   1.48   \n",
            "108     Nucleus Soft.  16.10  1.24  3.32     17.93  10.65       15.30   3.16   \n",
            "34      Bombay Burmah  12.25  0.86  2.45      6.07   4.19        7.90   0.74   \n",
            "11   Accelya Solution  16.27  6.48  7.47     14.32  10.09        6.32   3.92   \n",
            "57   Gulf Oil Lubric.  16.45  3.88  4.16     14.41   9.51        3.27   1.66   \n",
            "107   Dr Reddy's Labs  17.32  0.67  2.78     21.53  10.63        3.21   2.91   \n",
            "141      AGI Greenpac  15.06  0.85  2.39     12.38   8.14        1.86   2.00   \n",
            "111  Automotive Axles  16.35  1.79  2.55     20.02  10.32        1.60   1.26   \n",
            "\n",
            "     PE_Rank  PE_Decile  Div_Rank  Div_Decile  BV_Rank  BV_Decile  \\\n",
            "119     18.0          2      20.0           2      9.0          1   \n",
            "51      28.0          2       8.0           1     45.0          3   \n",
            "37      19.0          2      23.5           2     41.0          3   \n",
            "73      15.0          1      29.5           2     11.0          1   \n",
            "45      23.0          2      44.0           3     31.0          2   \n",
            "121      5.0          1      83.0           6     12.0          1   \n",
            "136     59.0          4      16.0           1     19.0          2   \n",
            "118      8.0          1       2.0           1      6.0          1   \n",
            "94       2.0          1      74.5           5      2.0          1   \n",
            "142      6.0          1      29.5           2      3.0          1   \n",
            "64       1.0          1      26.0           2      1.0          1   \n",
            "133     17.0          2      22.0           2      8.0          1   \n",
            "108      9.0          1      36.5           3     13.0          1   \n",
            "34       4.0          1      58.5           4      5.0          1   \n",
            "11      11.0          1       1.0           1     72.5          5   \n",
            "57      14.0          1       3.0           1     26.0          2   \n",
            "107     16.0          1      74.5           5     10.0          1   \n",
            "141      7.0          1      61.0           4      4.0          1   \n",
            "111     12.5          1      17.0           2      7.0          1   \n",
            "\n",
            "     Cashflow_Rank  Cashflow_Decile  EV_Rank  EV_Decile  Sales_Rank  \\\n",
            "119            4.0                1     18.0          2        28.0   \n",
            "51            31.0                2     30.0          2        33.0   \n",
            "37            20.0                2     17.0          2        20.5   \n",
            "73            18.0                2     14.0          1        49.5   \n",
            "45            15.0                1     23.0          2        46.0   \n",
            "121           13.0                1      7.0          1        12.0   \n",
            "136            7.0                1     45.0          3        14.0   \n",
            "118            2.0                1      4.0          1         8.5   \n",
            "94             3.0                1      3.0          1         7.0   \n",
            "142           12.0                1      6.0          1        11.0   \n",
            "64           107.0                7      1.0          1        10.0   \n",
            "133            6.0                1     11.0          1         6.0   \n",
            "108           14.0                1     13.0          1        41.0   \n",
            "34             1.0                1      2.0          1         1.0   \n",
            "11             8.0                1      9.0          1        56.0   \n",
            "57             9.0                1      8.0          1        13.0   \n",
            "107           19.0                2     12.0          1        35.0   \n",
            "141            5.0                1      5.0          1        18.0   \n",
            "111           17.0                2     10.0          1         2.0   \n",
            "\n",
            "     Sales_Decile  Consolidated_Rank  Consolidated_Decile  \n",
            "119             2                 10                    1  \n",
            "51              3                 13                    1  \n",
            "37              2                 13                    1  \n",
            "73              4                 11                    1  \n",
            "45              3                 13                    1  \n",
            "121             1                 11                    1  \n",
            "136             1                 12                    1  \n",
            "118             1                  6                    1  \n",
            "94              1                 10                    1  \n",
            "142             1                  7                    1  \n",
            "64              1                 13                    1  \n",
            "133             1                  8                    1  \n",
            "108             3                 10                    1  \n",
            "34              1                  9                    1  \n",
            "11              4                 13                    1  \n",
            "57              1                  7                    1  \n",
            "107             3                 13                    1  \n",
            "141             2                 10                    1  \n",
            "111             1                  8                    1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vc98poGk2Jka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}